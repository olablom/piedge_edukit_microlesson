#!/usr/bin/env python3
"""
Fix remaining Swedish phrases in notebooks by applying targeted replacements
to common end-of-notebook sections. Usage:

  python scripts/fix_language_notebooks.py notebooks/01_training_and_export.ipynb notebooks/02_latency_benchmark.ipynb

This script is idempotent â€“ running multiple times is safe.
"""

from __future__ import annotations

import json
import sys
from pathlib import Path


REPLACEMENTS = [
    # 01 â€” sections and headings
    (
        "# ğŸ§  TrÃ¤ning & ONNX Export - FÃ¶rstÃ¥ vad som hÃ¤nder",
        "# ğŸ§  Training & ONNX Export - Understand what's happening",
    ),
    (
        "**MÃ¥l**: FÃ¶rstÃ¥ hur trÃ¤ning fungerar och experimentera med olika instÃ¤llningar.",
        "**Goal**: Understand how training works and experiment with different settings.",
    ),
    ("I detta notebook kommer vi att:", "In this notebook we will:"),
    (
        "- FÃ¶rstÃ¥ vad FakeData Ã¤r och varfÃ¶r vi anvÃ¤nder det",
        "- Understand what FakeData is and why we use it",
    ),
    (
        "- Se hur dataset-pipeline â†’ modell â†’ loss/accuracy fungerar",
        "- See how dataset-pipeline â†’ model â†’ loss/accuracy works",
    ),
    (
        "- Experimentera med olika hyperparametrar",
        "- Experiment with different hyperparameters",
    ),
    ("- FÃ¶rstÃ¥ varfÃ¶r vi exporterar till ONNX", "- Understand why we export to ONNX"),
    (
        "> **ğŸ’¡ Tips**: KÃ¶r cellerna i ordning och lÃ¤s fÃ¶rklaringarna. Experimentera gÃ¤rna med vÃ¤rdena!",
        "> **ğŸ’¡ Tip**: Run the cells in order and read the explanations. Feel free to experiment with the values!",
    ),
    (
        "## ğŸ¤” Vad Ã¤r FakeData och varfÃ¶r anvÃ¤nder vi det?",
        "## ğŸ¤” What is FakeData and why do we use it?",
    ),
    (
        "**FakeData** Ã¤r syntetiska bilder som PyTorch genererar automatiskt. Det Ã¤r perfekt fÃ¶r:",
        "**FakeData** are synthetic images that PyTorch generates automatically. It's perfect for:",
    ),
    (
        "- **Snabb prototyping** - ingen nedladdning av stora dataset",
        "- **Quick prototyping** - no downloading of large datasets",
    ),
    (
        "- **Reproducerbarhet** - samma data varje gÃ¥ng",
        "- **Reproducibility** - same data every time",
    ),
    (
        "- **Undervisning** - fokus pÃ¥ algoritmer, inte datahantering",
        "- **Teaching** - focus on algorithms, not data management",
    ),
    (
        "<summary>ğŸ” Klicka fÃ¶r att se vad FakeData innehÃ¥ller</summary>",
        "<summary>ğŸ” Click to see what FakeData contains</summary>",
    ),
    ("# FakeData genererar:", "# FakeData generates:"),
    (
        "# - SlumpmÃ¤ssiga RGB-bilder (64x64 pixlar)",
        "# - Random RGB images (64x64 pixels)",
    ),
    ("# - SlumpmÃ¤ssiga klasser (0, 1, 2, ...)", "# - Random classes (0, 1, 2, ...)"),
    (
        "# - Samma struktur som riktiga bilddataset",
        "# - Same structure as real image datasets",
    ),
    (
        "# LÃ¥t oss skapa en liten FakeData fÃ¶r att se vad den innehÃ¥ller",
        "# Let's create a small FakeData to see what it contains",
    ),
    ("# Skapa FakeData med 2 klasser", "# Create FakeData with 2 classes"),
    ("# Visa fÃ¶rsta bilden", "# Show first image"),
    ('print(f"Bildstorlek: {image.size}")', 'print(f"Image size: {image.size}")'),
    ('print(f"Klass: {label}")', 'print(f"Class: {label}")'),
    (
        'print(f"PixelvÃ¤rden: {image.getextrema()}")',
        'print(f"Pixel values: {image.getextrema()}")',
    ),
    ("# Visa bilden", "# Show the image"),
    (
        'plt.title(f"FakeData - Klass {label}")',
        'plt.title(f"FakeData - Class {label}")',
    ),
    ("## ğŸ¤” ReflektionsfrÃ¥gor", "## ğŸ¤” Reflection Questions"),
    (
        "<summary>ğŸ’­ Vad hÃ¤nder med Ã¶verfitting nÃ¤r du hÃ¶jer epochs?</summary>",
        "<summary>ğŸ’­ What happens with overfitting when you increase epochs?</summary>",
    ),
    (
        "**Svar**: Med fler epochs kan modellen lÃ¤ra sig trÃ¤ningsdata fÃ¶r bra och dÃ¥ligt generalisera till nya data. Detta kallas Ã¶verfitting.",
        "**Answer**: With more epochs, the model can learn the training data too well and generalize poorly to new data. This is called overfitting.",
    ),
    (
        "**Experiment**: KÃ¶r samma trÃ¤ning men med `--epochs 5` och jÃ¤mfÃ¶r accuracy pÃ¥ trÃ¤nings- vs valideringsdata.",
        "**Experiment**: Run the same training but with `--epochs 5` and compare accuracy on training vs validation data.",
    ),
    (
        "<summary>ğŸ’­ VarfÃ¶r exporterar vi till ONNX (fÃ¶r Pi/edge)?</summary>",
        "<summary>ğŸ’­ Why do we export to ONNX (for Pi/edge)?</summary>",
    ),
    (
        "**Svar**: ONNX Ã¤r ett standardformat som fungerar pÃ¥ mÃ¥nga plattformar (CPU, GPU, mobil, edge). Det gÃ¶r modellen portabel och optimerad fÃ¶r inference.",
        "**Answer**: ONNX is a standard format that works on many platforms (CPU, GPU, mobile, edge). It makes the model portable and optimized for inference.",
    ),
    ("**FÃ¶rdelar**:", "**Benefits**:"),
    ("- Snabbare inference Ã¤n PyTorch", "- Faster inference than PyTorch"),
    ("- Mindre minnesanvÃ¤ndning", "- Less memory usage"),
    ("- Fungerar pÃ¥ Raspberry Pi", "- Works on Raspberry Pi"),
    ("- StÃ¶d fÃ¶r kvantisering (INT8)", "- Support for quantization (INT8)"),
    ("## ğŸ¯ Ditt eget experiment", "## ğŸ¯ Your own experiment"),
    (
        "**Uppgift**: TrÃ¤na en modell med andra instÃ¤llningar och jÃ¤mfÃ¶r resultaten.",
        "**Task**: Train a model with different settings and compare the results.",
    ),
    ("**FÃ¶rslag**:", "**Suggestions**:"),
    ("- Ã–ka epochs till 3-5", "- Increase epochs to 3-5"),
    ("- Ã„ndra batch_size till 64 eller 256", "- Change batch_size to 64 or 256"),
    (
        "- Testa med och utan `--no-pretrained`",
        "- Test with and without `--no-pretrained`",
    ),
    ("**Kod att modifiera**:", "**Code to modify**:"),
    ("# Ã„ndra dessa vÃ¤rden:", "# Change these values:"),
    (
        "USE_PRETRAINED = False  # True fÃ¶r fÃ¶rtrÃ¤nade vikter",
        "USE_PRETRAINED = False  # True for pretrained weights",
    ),
    (
        "# TODO: Implementera ditt experiment hÃ¤r",
        "# TODO: Implement your experiment here",
    ),
    (
        "# Ã„ndra vÃ¤rdena nedan och kÃ¶r trÃ¤ningen",
        "# Change the values below and run the training",
    ),
    (
        'print(f"ğŸ§ª Mitt experiment: epochs={EPOCHS}, batch_size={BATCH_SIZE}, pretrained={USE_PRETRAINED}")',
        'print(f"ğŸ§ª My experiment: epochs={EPOCHS}, batch_size={BATCH_SIZE}, pretrained={USE_PRETRAINED}")',
    ),
    (
        "# TODO: KÃ¶r trÃ¤ningen med dina instÃ¤llningar",
        "# TODO: Run the training with your settings",
    ),
    ("## ğŸ‰ Sammanfattning", "## ğŸ‰ Summary"),
    ("you have nu lÃ¤rt dig:", "You have now learned:"),
    (
        "- Vad FakeData Ã¤r och varfÃ¶r vi anvÃ¤nder det",
        "- What FakeData is and why we use it",
    ),
    (
        "- Hur trÃ¤ning fungerar med olika hyperparametrar",
        "- How training works with different hyperparameters",
    ),
    (
        "- VarfÃ¶r ONNX-export Ã¤r viktigt fÃ¶r edge deployment",
        "- Why ONNX export is important for edge deployment",
    ),
    (
        "**NÃ¤sta steg**: GÃ¥ till `02_latency_benchmark.ipynb` fÃ¶r att fÃ¶rstÃ¥ hur vi mÃ¤ter modellens prestanda.",
        "**Next step**: Go to `02_latency_benchmark.ipynb` to understand how we measure model performance.",
    ),
    ("**Viktiga begrepp**:", "**Key concepts**:"),
    (
        "- **Epochs**: Antal genomgÃ¥ngar av datasetet",
        "- **Epochs**: Number of passes through the dataset",
    ),
    (
        "- **Batch size**: Antal bilder per trÃ¤ningssteg",
        "- **Batch size**: Number of images per training step",
    ),
    (
        "- **Pretrained weights**: FÃ¶rtrÃ¤nade vikter frÃ¥n ImageNet",
        "- **Pretrained weights**: Pre-trained weights from ImageNet",
    ),
    (
        "- **ONNX**: Standardformat fÃ¶r edge deployment",
        "- **ONNX**: Standard format for edge deployment",
    ),
    # 02 â€” tail section translations
    (
        "# âš¡ Latensbenchmark - FÃ¶rstÃ¥ modellens prestanda",
        "# âš¡ Latency Benchmark - Understand model performance",
    ),
    (
        "## 3ï¸âƒ£ Latensbenchmark",
        "## 3ï¸âƒ£ Latency Benchmark",
    ),
    (
        "**MÃ¥l**: FÃ¶rstÃ¥ hur vi mÃ¤ter och tolkar modellens latens (svarstid).",
        "**Goal**: Understand how we measure and interpret model latency (response time).",
    ),
    (
        "Measuring how fast the model is pÃ¥ CPU:",
        "Measuring how fast the model is on CPU:",
    ),
    ("I detta notebook kommer vi att:", "In this notebook we will:"),
    (
        "- FÃ¶rstÃ¥ vad latens Ã¤r och varfÃ¶r det Ã¤r viktigt",
        "- Understand what latency is and why it's important",
    ),
    (
        "- Se hur benchmark fungerar (warmup, runs, providers)",
        "- See how benchmark works (warmup, runs, providers)",
    ),
    (
        "- Tolka resultat (p50, p95, histogram)",
        "- Interpret results (p50, p95, histogram)",
    ),
    ("- Experimentera med olika instÃ¤llningar", "- Experiment with different settings"),
    (
        "> **ğŸ’¡ Tips**: Latens Ã¤r avgÃ¶rande fÃ¶r edge deployment - en modell som Ã¤r fÃ¶r lÃ¥ngsam Ã¤r inte anvÃ¤ndbar i verkligheten!",
        "> **ğŸ’¡ Tip**: Latency is critical for edge deployment - a model that's too slow is not usable in real life!",
    ),
    (
        "## ğŸ¤” Vad Ã¤r latens och varfÃ¶r Ã¤r det viktigt?",
        "## ğŸ¤” What is latency and why is it important?",
    ),
    (
        "**Latens** = tiden det tar fÃ¶r modellen att gÃ¶ra en fÃ¶rutsÃ¤gelse (inference time).",
        "**Latency** = the time it takes for the model to make a prediction (inference time).",
    ),
    ("**VarfÃ¶r viktigt fÃ¶r edge**:", "**Why important for edge**:"),
    (
        "- **Realtidsapplikationer** - robotar, autonoma fordon",
        "- **Real-time applications** - robots, autonomous vehicles",
    ),
    (
        "- **AnvÃ¤ndarupplevelse** - ingen vill vÃ¤nta 5 sekunder pÃ¥ en bildklassificering",
        "- **User experience** - no one wants to wait 5 seconds for image classification",
    ),
    (
        "- **ResursbegrÃ¤nsningar** - Raspberry Pi har begrÃ¤nsad CPU/memory",
        "- **Resource constraints** - Raspberry Pi has limited CPU/memory",
    ),
    (
        "<summary>ğŸ” Klicka fÃ¶r att se typiska latensmÃ¥l</summary>",
        "<summary>ğŸ” Click to see typical latency targets</summary>",
    ),
    ("**Typiska latensmÃ¥l**:", "**Typical latency targets**:"),
    ("- **< 10ms**: Realtidsvideo, gaming", "- **< 10ms**: Real-time video, gaming"),
    (
        "- **< 100ms**: Interaktiva applikationer",
        "- **< 100ms**: Interactive applications",
    ),
    (
        "- **< 1000ms**: Batch processing, offline analys",
        "- **< 1000ms**: Batch processing, offline analysis",
    ),
    (
        "**VÃ¥r modell**: FÃ¶rvÃ¤ntar oss ~1-10ms pÃ¥ CPU (bra fÃ¶r edge!)",
        "**Our model**: Expect ~1-10ms on CPU (good for edge!)",
    ),
    ("## ğŸ”§ Hur fungerar benchmark?", "## ğŸ”§ How does benchmark work?"),
    ("**Benchmark-processen**:", "**Benchmark process**:"),
    (
        '1. **Warmup** - kÃ¶r modellen nÃ¥gra gÃ¥nger fÃ¶r att "vÃ¤rmma upp" (JIT compilation, cache)',
        '1. **Warmup** - run the model a few times to "warm up" (JIT compilation, cache)',
    ),
    (
        "2. **Runs** - mÃ¤ter latens fÃ¶r mÃ¥nga kÃ¶rningar",
        "2. **Runs** - measure latency for many runs",
    ),
    (
        "3. **Statistik** - berÃ¤knar p50, p95, mean, std",
        "3. **Statistics** - calculate p50, p95, mean, std",
    ),
    ("**VarfÃ¶r warmup?**", "**Why warmup?**"),
    (
        "- FÃ¶rsta kÃ¶rningen Ã¤r ofta lÃ¥ngsam (JIT compilation)",
        "- First run is often slow (JIT compilation)",
    ),
    ("- Cache-vÃ¤rme pÃ¥verkar prestanda", "- Cache warming affects performance"),
    (
        '- Vi vill mÃ¤ta "steady state" prestanda',
        '- We want to measure "steady state" performance',
    ),
    ('print("ğŸš€ KÃ¶r benchmark...")', 'print("ğŸš€ Running benchmark...")'),
    ('print("ğŸ“ˆ Benchmark-resultat:")', 'print("ğŸ“ˆ Benchmark results:")'),
    ('print(f"ğŸ“Š Latens-statistik:")', 'print(f"ğŸ“Š Latency statistics:")'),
    ('print(f"Antal mÃ¤tningar: {len(df)}")', 'print(f"Num measurements: {len(df)}")'),
    ("plt.xlabel('Latens (ms)')", "plt.xlabel('Latency (ms)')"),
    ("plt.ylabel('Antal')", "plt.ylabel('Count')"),
    ("plt.title('Latens-distribution')", "plt.title('Latency distribution')"),
    ("plt.ylabel('Latens (ms)')", "plt.ylabel('Latency (ms)')"),
    ("plt.title('Latens Box Plot')", "plt.title('Latency Box Plot')"),
    ('print("âŒ Latens CSV missing")', 'print("âŒ Latency CSV missing")'),
    ("# KÃ¶r benchmark (snabb running)", "# Run benchmark (quick mode)"),
    # 02 â€” summary & key concepts tail section
    ("## ğŸ‰ Sammanfattning", "## ğŸ‰ Summary"),
    ("you have nu lÃ¤rt dig:", "You have now learned:"),
    (
        "- Vad latens Ã¤r och varfÃ¶r det Ã¤r kritiskt fÃ¶r edge deployment",
        "- What latency is and why it is critical for edge deployment",
    ),
    (
        "- Hur benchmark fungerar (warmup, runs, statistik)",
        "- How the benchmark works (warmup, runs, statistics)",
    ),
    (
        "- Hur man tolkar latens-resultat (p50, p95, varians)",
        "- How to interpret latency results (p50, p95, variance)",
    ),
    (
        "- VarfÃ¶r p95 Ã¤r viktigare Ã¤n mean fÃ¶r anvÃ¤ndarupplevelse",
        "- Why P95 is more important than mean for user experience",
    ),
    (
        "**NÃ¤sta steg**: GÃ¥ till `03_quantization.ipynb` fÃ¶r att fÃ¶rstÃ¥ hur kvantisering kan fÃ¶rbÃ¤ttra prestanda.",
        "**Next step**: Go to `03_quantization.ipynb` to understand how quantization can improve performance.",
    ),
    ("**Viktiga begrepp**:", "**Key concepts**:"),
    (
        "- **Latens**: Inference-tid (kritiskt fÃ¶r edge)",
        "- **Latency**: Inference time (critical for edge)",
    ),
    (
        "- **Warmup**: FÃ¶rbereder modellen fÃ¶r mÃ¤tning",
        "- **Warm-up**: Prepares the model for measurement",
    ),
    (
        "- **p50/p95**: Percentiler fÃ¶r latens-distribution",
        "- **p50/p95**: Percentiles for the latency distribution",
    ),
    (
        "- **Varians**: Konsistens i prestanda",
        "- **Variance**: Consistency in performance",
    ),
    # 03 â€” Quantization notebook (body + tail)
    (
        "# âš¡ Kvantisering (INT8) - Komprimera modellen fÃ¶r snabbare inference",
        "# âš¡ Quantization (INT8) - Compress the model for faster inference",
    ),
    (
        "## 4ï¸âƒ£ Kvantisering (INT8)",
        "## 4ï¸âƒ£ Quantization (INT8)",
    ),
    (
        "**MÃ¥l**: FÃ¶rstÃ¥ hur kvantisering fungerar och nÃ¤r det Ã¤r vÃ¤rt det.",
        "**Goal**: Understand how quantization works and when it is worth it.",
    ),
    (
        "Compressing the model fÃ¶r snabbare inference:",
        "Compressing the model for faster inference:",
    ),
    (
        "- FÃ¶rstÃ¥ vad kvantisering Ã¤r (FP32 â†’ INT8)",
        "- Understand what quantization is (FP32 â†’ INT8)",
    ),
    (
        "- Se hur det pÃ¥verkar modellstorlek och latens",
        "- See how it affects model size and latency",
    ),
    (
        "- Experimentera med olika kalibreringsstorlekar",
        "- Experiment with different calibration sizes",
    ),
    (
        "- FÃ¶rstÃ¥ kompromisser (accuracy vs prestanda)",
        "- Understand the trade-offs (accuracy vs performance)",
    ),
    ("## ğŸ¤” Vad Ã¤r kvantisering?", "## ğŸ¤” What is quantization?"),
    (
        "**Kvantisering** = konvertera modellen frÃ¥n 32-bit flyttal (FP32) till 8-bit heltal (INT8).",
        "**Quantization** = convert the model from 32-bit floating point (FP32) to 8-bit integers (INT8).",
    ),
    (
        "- **4x mindre modellstorlek** (32 bit â†’ 8 bit)",
        "- **4x smaller model size** (32-bit â†’ 8-bit)",
    ),
    (
        "- **2-4x snabbare inference** (INT8 Ã¤r snabbare att berÃ¤kna)",
        "- **2â€“4x faster inference** (INT8 is faster to compute)",
    ),
    (
        "- **Mindre minnesanvÃ¤ndning** (viktigt fÃ¶r edge)",
        "- **Lower memory usage** (important for edge)",
    ),
    ("**Kompromisser**:", "**Trade-offs**:"),
    (
        "- **Accuracy-fÃ¶rlust** - modellen kan bli mindre exakt",
        "- **Accuracy loss** â€” the model can become less accurate",
    ),
    (
        "- **Kalibrering required** - behÃ¶ver representativ data fÃ¶r att hitta rÃ¤tt skala",
        "- **Calibration required** â€” needs representative data to find proper scales",
    ),
    (
        "<summary>ğŸ” Klicka fÃ¶r att se tekniska detaljer</summary>",
        "<summary>ğŸ” Click to see technical details</summary>",
    ),
    ("**Teknisk fÃ¶rklaring**:", "**Technical details**:"),
    ("- FP32: 32 bit per vikt (4 bytes)", "- FP32: 32 bits per weight (4 bytes)"),
    ("- INT8: 8 bit per vikt (1 byte)", "- INT8: 8 bits per weight (1 byte)"),
    (
        "- Kvantisering hittar rÃ¤tt skala fÃ¶r varje vikt",
        "- Quantization finds the right scale for each weight",
    ),
    (
        "- Kalibrering anvÃ¤nder representativ data fÃ¶r att optimera skalan",
        "- Calibration uses representative data to optimize scales",
    ),
    (
        "# FÃ¶rst skapar vi en modell att kvantisera",
        "# First create a model to quantize",
    ),
    (
        'print("ğŸš€ Skapar modell fÃ¶r kvantisering...")',
        'print("ğŸš€ Creating a model for quantization...")',
    ),
    (
        'print(f"ğŸ“¦ Ursprunglig modellstorlek: {original_size:.2f} MB")',
        'print(f"ğŸ“¦ Original model size: {original_size:.2f} MB")',
    ),
    ('print("âŒ Modell missing")', 'print("âŒ Model missing")'),
    (
        "## ğŸ§ª Experimentera med olika kalibreringsstorlekar",
        "## ğŸ§ª Experiment with different calibration sizes",
    ),
    (
        "**Kalibreringsstorlek** = antal bilder som anvÃ¤nds fÃ¶r att hitta rÃ¤tt skala fÃ¶r kvantisering.",
        "**Calibration size** = number of images used to find the right quantization scales.",
    ),
    ("**StÃ¶rre kalibrering**:", "**Larger calibration**:"),
    (
        "- âœ… BÃ¤ttre accuracy (mer representativ data)",
        "- âœ… Better accuracy (more representative data)",
    ),
    ("- âŒ LÃ¤ngre kvantiserings-tid", "- âŒ Longer quantization time"),
    ("- âŒ Mer minne under kvantisering", "- âŒ More memory during quantization"),
    ("**Mindre kalibrering**:", "**Smaller calibration**:"),
    ("- âœ… Snabbare kvantisering", "- âœ… Faster quantization"),
    ("- âœ… Mindre minnesanvÃ¤ndning", "- âœ… Lower memory usage"),
    ("- âŒ Potentiellt sÃ¤mre accuracy", "- âŒ Potentially worse accuracy"),
    (
        'print("âš¡ Test 1: Liten kalibrering (16 bilder)")',
        'print("âš¡ Test 1: Small calibration (16 images)")',
    ),
    ("# Visa kvantiseringsresultat", "# Show quantization results"),
    ('print("ğŸ“Š Kvantiseringsresultat:")', 'print("ğŸ“Š Quantization results:")'),
    (
        'print("âŒ Kvantiseringsrapport missing")',
        'print("âŒ Quantization report missing")',
    ),
    ("# JÃ¤mfÃ¶r modellstorlekar", "# Compare model sizes"),
    ('print("ğŸ“¦ Modellstorlekar:")', 'print("ğŸ“¦ Model sizes:")'),
    (
        'print(f"  Ursprunglig (FP32): {original_size:.2f} MB")',
        'print(f"  Original (FP32): {original_size:.2f} MB")',
    ),
    (
        'print(f"  Kvantiserad (INT8): {quantized_size:.2f} MB")',
        'print(f"  Quantized (INT8): {quantized_size:.2f} MB")',
    ),
    (
        'print(f"  Komprimering: {original_size/quantized_size:.1f}x")',
        'print(f"  Compression: {original_size/quantized_size:.1f}x")',
    ),
    ('print("âŒ Modellfiler missing")', 'print("âŒ Model files missing")'),
    (
        'print("ğŸš€ Benchmark ursprunglig modell (FP32)...")',
        'print("ğŸš€ Benchmark original model (FP32)...")',
    ),
    (
        'print("âš¡ Benchmark kvantiserad modell (INT8)...")',
        'print("âš¡ Benchmark quantized model (INT8)...")',
    ),
    ('print(f"ğŸ“Š Latens-jÃ¤mfÃ¶relse:")', 'print(f"ğŸ“Š Latency comparison:")'),
    (
        'print(f"  FP32 (ursprunglig): {fp32_mean:.2f} ms")',
        'print(f"  FP32 (original): {fp32_mean:.2f} ms")',
    ),
    (
        'print(f"  FP32: Kunde inte parsa latens")',
        'print(f"  FP32: Could not parse latency")',
    ),
    (
        'print(f"  INT8 (kvantiserad): [kommer efter benchmark]")',
        'print(f"  INT8 (quantized): [after benchmark]")',
    ),
    ('print("âŒ Benchmark-rapport missing")', 'print("âŒ Benchmark report missing")'),
    (
        "<summary>ğŸ’­ NÃ¤r Ã¤r INT8-kvantisering vÃ¤rt det?</summary>",
        "<summary>ğŸ’­ When is INT8 quantization worth it?</summary>",
    ),
    ("**Svar**: INT8 Ã¤r vÃ¤rt det nÃ¤r:", "**Answer**: INT8 is worth it when:"),
    (
        "- **Latens Ã¤r kritisk** - realtidsapplikationer, edge deployment",
        "- **Latency is critical** â€” real-time applications, edge deployment",
    ),
    (
        "- **Minne Ã¤r begrÃ¤nsat** - mobil, Raspberry Pi",
        "- **Memory is limited** â€” mobile, Raspberry Pi",
    ),
    (
        "- **Accuracy-fÃ¶rlusten Ã¤r acceptabel** - < 1-2% accuracy-fÃ¶rlust Ã¤r ofta OK",
        "- **Accuracy loss is acceptable** â€” < 1â€“2% accuracy drop is often OK",
    ),
    (
        "- **Batch size Ã¤r liten** - kvantisering fungerar bÃ¤st med smÃ¥ batches",
        "- **Batch size is small** â€” quantization often works best with small batches",
    ),
    ("**NÃ¤r INTE vÃ¤rt det**:", "**When NOT worth it**:"),
    ("- Accuracy Ã¤r absolut kritisk", "- Accuracy is absolutely critical"),
    ("- you have gott om minne och CPU", "- You have ample memory and CPU"),
    ("- Modellen Ã¤r redan snabb nog", "- The model is already fast enough"),
    (
        "<summary>ğŸ’­ Vilka risker finns med kvantisering?</summary>",
        "<summary>ğŸ’­ What are the risks with quantization?</summary>",
    ),
    ("**Svar**: Huvudrisker:", "**Answer**: Main risks:"),
    (
        "- **Accuracy-fÃ¶rlust** - modellen kan bli mindre exakt",
        "- **Accuracy loss** â€” the model can become less accurate",
    ),
    (
        "- **Kalibreringsdata** - behÃ¶ver representativ data fÃ¶r bra kvantisering",
        "- **Calibration data** â€” needs representative data for good quantization",
    ),
    (
        "- **Edge cases** - extrema vÃ¤rden kan orsaka problem",
        "- **Edge cases** â€” extreme values can cause issues",
    ),
    (
        "- **Debugging** - kvantiserade modeller Ã¤r svÃ¥rare att debugga",
        "- **Debugging** â€” quantized models are harder to debug",
    ),
    ("**Minskning**:", "**Mitigation**:"),
    ("- Testa noggrant med riktig data", "- Test thoroughly with real data"),
    ("- AnvÃ¤nd olika kalibreringsstorlekar", "- Use different calibration sizes"),
    ("- Benchmark bÃ¥de accuracy och latens", "- Benchmark both accuracy and latency"),
    (
        "**Uppgift**: Testa olika kalibreringsstorlekar och jÃ¤mfÃ¶r resultaten.",
        "**Task**: Test different calibration sizes and compare the results.",
    ),
    (
        "- Testa kalibreringsstorlekar: 8, 16, 32, 64",
        "- Try calibration sizes: 8, 16, 32, 64",
    ),
    ("- JÃ¤mfÃ¶r modellstorlek och latens", "- Compare model size and latency"),
    (
        "- Analysera accuracy-fÃ¶rlust (om tillgÃ¤nglig)",
        "- Analyze accuracy loss (if available)",
    ),
    (
        "# Ã„ndra vÃ¤rdena nedan och kÃ¶r kvantisering",
        "# Change the values below and run quantization",
    ),
    (
        'print(f"ğŸ§ª Mitt experiment: kalibreringsstorlek={CALIB_SIZE}")',
        'print(f"ğŸ§ª My experiment: calibration_size={CALIB_SIZE}")',
    ),
    (
        "# TODO: KÃ¶r kvantisering med din instÃ¤llning",
        "# TODO: Run quantization with your setting",
    ),
    (
        "- Vad kvantisering Ã¤r (FP32 â†’ INT8) och varfÃ¶r det Ã¤r viktigt",
        "- What quantization is (FP32 â†’ INT8) and why it matters",
    ),
    (
        "- Hur kalibreringsstorlek pÃ¥verkar resultatet",
        "- How calibration size affects the result",
    ),
    (
        "- Kompromisser mellan accuracy och prestanda",
        "- Trade-offs between accuracy and performance",
    ),
    (
        "- NÃ¤r kvantisering Ã¤r vÃ¤rt det vs nÃ¤r det inte Ã¤r det",
        "- When quantization is worth it vs when it is not",
    ),
    (
        "**NÃ¤sta steg**: GÃ¥ till `04_evaluate_and_verify.ipynb` fÃ¶r att fÃ¶rstÃ¥ automatiska checks och kvittogenerering.",
        "**Next**: Open `04_evaluate_and_verify.ipynb` to understand automated checks and receipt generation.",
    ),
    (
        "- **Kvantisering**: FP32 â†’ INT8 fÃ¶r snabbare inference",
        "- **Quantization**: FP32 â†’ INT8 for faster inference",
    ),
    (
        "- **Kalibrering**: Representativ data fÃ¶r att hitta rÃ¤tt skala",
        "- **Calibration**: Representative data to find the right scales",
    ),
    (
        "- **Komprimering**: 4x mindre modellstorlek",
        "- **Compression**: 4x smaller model size",
    ),
    ("- **Speedup**: 2-4x snabbare inference", "- **Speedup**: 2â€“4x faster inference"),
    # 04 â€” Evaluation & Verification (body + tail)
    (
        "## ğŸ¤” Vad Ã¤r utvÃ¤rdering och varfÃ¶r behÃ¶ver vi det?",
        "## ğŸ¤” What is evaluation and why do we need it?",
    ),
    (
        "## 5ï¸âƒ£ UtvÃ¤rdering & Verifiering",
        "## 5ï¸âƒ£ Evaluation & Verification",
    ),
    (
        "**UtvÃ¤rdering** = testa modellen pÃ¥ data den inte har sett under trÃ¤ning.",
        "**Evaluation** = test the model on data it has not seen during training.",
    ),
    ("**Vad vi mÃ¤ter**:", "**What we measure**:"),
    (
        "- **Accuracy** - hur mÃ¥nga fÃ¶rutsÃ¤gelser som Ã¤r rÃ¤tta",
        "- **Accuracy** â€” how many predictions are correct",
    ),
    (
        "- **Confusion matrix** - detaljerad breakdown av rÃ¤tta/felaktiga fÃ¶rutsÃ¤gelser",
        "- **Confusion matrix** â€” detailed breakdown of correct/incorrect predictions",
    ),
    (
        "- **Per-class performance** - hur bra modellen Ã¤r pÃ¥ varje klass",
        "- **Per-class performance** â€” how well the model performs for each class",
    ),
    ("**VarfÃ¶r viktigt**:", "**Why important**:"),
    (
        "- **Validering** - sÃ¤kerstÃ¤ller att modellen faktiskt fungerar",
        "- **Validation** â€” ensures the model actually works",
    ),
    (
        "- **Debugging** - visar vilka klasser som Ã¤r svÃ¥ra",
        "- **Debugging** â€” shows which classes are difficult",
    ),
    (
        "- **JÃ¤mfÃ¶relse** - kan jÃ¤mfÃ¶ra olika modeller/instÃ¤llningar",
        "- **Comparison** â€” compare different models/settings",
    ),
    (
        "<summary>ğŸ” Klicka fÃ¶r att se vad en confusion matrix visar</summary>",
        "<summary>ğŸ” Click to see what a confusion matrix shows</summary>",
    ),
    ("# KÃ¶r utvÃ¤rdering pÃ¥ vÃ¥r modell", "# Run evaluation on our model"),
    ('print("ğŸ” KÃ¶r utvÃ¤rdering...")', 'print("ğŸ” Running evaluation...")'),
    (
        "# AnvÃ¤nd modellen frÃ¥n fÃ¶regÃ¥ende notebooks (eller skapa en snabb)",
        "# Use the model from previous notebooks (or create a quick one)",
    ),
    (
        "# KÃ¶r utvÃ¤rdering med begrÃ¤nsat antal samples (snabbare)",
        "# Run evaluation with a limited number of samples (faster)",
    ),
    ("# Visa utvÃ¤rderingsresultat", "# Show evaluation results"),
    ('print("ğŸ“Š UtvÃ¤rderingsresultat:")', 'print("ğŸ“Š Evaluation results:")'),
    (
        'print("âŒ UtvÃ¤rderingsrapport missing")',
        'print("âŒ Evaluation report missing")',
    ),
    ("# Visa trÃ¤ningsgrafer om de finns", "# Show training curves if available"),
    ('print("ğŸ“ˆ TrÃ¤ningsgrafer:")', 'print("ğŸ“ˆ Training curves:")'),
    (
        'print("âš ï¸ TrÃ¤ningsgrafer missing â€“ kÃ¶r trÃ¤ningen fÃ¶rst.")',
        'print("âš ï¸ Training curves missing â€“ run training first.")',
    ),
    ("## ğŸ” Automatisk verifiering", "## ğŸ” Automatic verification"),
    (
        "**Verifiering** = automatiska checks som sÃ¤kerstÃ¤ller att lektionen fungerar korrekt.",
        "**Verification** = automated checks ensuring the lesson works correctly.",
    ),
    ("**Vad kontrolleras**:", "**What is checked**:"),
    (
        "- **Artefakter finns** - alla nÃ¶dvÃ¤ndiga filer Ã¤r skapade",
        "- **Artifacts exist** â€” all required files are created",
    ),
    (
        "- **Benchmark fungerar** - latens-data Ã¤r giltig",
        "- **Benchmark works** â€” latency data is valid",
    ),
    (
        "- **Kvantisering fungerar** - kvantiserad modell Ã¤r skapad",
        "- **Quantization works** â€” quantized model is created",
    ),
    (
        "- **UtvÃ¤rdering fungerar** - confusion matrix och accuracy Ã¤r tillgÃ¤nglig",
        "- **Evaluation works** â€” confusion matrix and accuracy are available",
    ),
    (
        "**Resultat**: `progress/receipt.json` med PASS/FAIL status",
        "**Result**: `progress/receipt.json` with PASS/FAIL status",
    ),
    ("# KÃ¶r automatisk verifiering", "# Run automatic verification"),
    (
        'print("ğŸ” KÃ¶r automatisk verifiering...")',
        'print("ğŸ” Running automatic verification...")',
    ),
    (
        "ğŸ“‹ Verifieringskvitto:",
        "ğŸ“‹ Verification receipt:",
    ),
    (
        "Kontroller:",
        "Checks:",
    ),
    (
        "# Visa kvitto",
        "# Show receipt",
    ),
    (
        'print("\nKontroller:")',
        'print("\nChecks:")',
    ),
    ("# Analysera kvittot i detalj", "# Analyze the receipt in detail"),
    ('print("ğŸ“‹ Detaljerad kvitto-analys:")', 'print("ğŸ“‹ Detailed receipt analysis:")'),
    ('print("\nğŸ” Kontroller:")', 'print("\nğŸ” Checks:")'),
    ('print("\nğŸ“ Genererade filer:")', 'print("\nğŸ“ Generated files:")'),
    ('print("âŒ Kvitto missing")', 'print("âŒ Receipt missing")'),
    (
        "<summary>ğŸ’­ Vilka mÃ¥l verifieras av vÃ¥r automatiska check?</summary>",
        "<summary>ğŸ’­ Which goals are verified by our automatic check?</summary>",
    ),
    ("**Svar**: VÃ¥r verifiering kontrollerar:", "**Answer**: Our verification checks:"),
    (
        "- **Teknisk funktionalitet** - alla steg kÃ¶rs utan fel",
        "- **Technical functionality** â€” all steps run without errors",
    ),
    (
        "- **Artefakt-generering** - nÃ¶dvÃ¤ndiga filer skapas",
        "- **Artifact generation** â€” required files are created",
    ),
    (
        "- **Data-integritet** - rapporter Ã¤r giltiga och parseable",
        "- **Data integrity** â€” reports are valid and parseable",
    ),
    (
        "- **Pipeline-integration** - alla komponenter fungerar tillsammans",
        "- **Pipeline integration** â€” all components work together",
    ),
    ("**Vad som INTE verifieras**:", "**What is NOT verified**:"),
    (
        "- Accuracy-kvalitet (bara att utvÃ¤rdering kÃ¶rs)",
        "- Accuracy quality (only that evaluation runs)",
    ),
    (
        "- Latens-mÃ¥l (bara att benchmark kÃ¶rs)",
        "- Latency targets (only that benchmark runs)",
    ),
    (
        "- Produktionsredo (bara att pipeline fungerar)",
        "- Production readiness (only that the pipeline works)",
    ),
    (
        '<summary>ğŸ’­ Vad missing fÃ¶r "produktion"?</summary>',
        '<summary>ğŸ’­ What is missing for "production"?</summary>',
    ),
    ("**Svar**: FÃ¶r produktion behÃ¶ver vi:", "**Answer**: For production we need:"),
    ("- **Riktig data** - inte FakeData", "- **Real data** â€” not FakeData"),
    (
        "- **Accuracy-mÃ¥l** - specifika krav pÃ¥ precision/recall",
        "- **Accuracy targets** â€” specific precision/recall requirements",
    ),
    (
        "- **Latens-mÃ¥l** - SLA-krav pÃ¥ inference-tid",
        "- **Latency targets** â€” SLA requirements on inference time",
    ),
    (
        "- **Robusthet** - hantering av edge cases och fel",
        "- **Robustness** â€” handling of edge cases and errors",
    ),
    (
        "- **Monitoring** - kontinuerlig Ã¶vervakning av prestanda",
        "- **Monitoring** â€” continuous monitoring of performance",
    ),
    (
        "- **A/B-testing** - jÃ¤mfÃ¶relse av olika modeller",
        "- **A/B testing** â€” comparison of different models",
    ),
    (
        "- **Rollback** - mÃ¶jlighet att gÃ¥ tillbaka till tidigare version",
        "- **Rollback** â€” ability to revert to previous versions",
    ),
    (
        "**Uppgift**: KÃ¶r verifiering pÃ¥ olika modeller och jÃ¤mfÃ¶r kvittona.",
        "**Task**: Run verification on different models and compare receipts.",
    ),
    (
        "- TrÃ¤na modeller med olika instÃ¤llningar",
        "- Train models with different settings",
    ),
    ("- KÃ¶r verifiering pÃ¥ varje modell", "- Run verification on each model"),
    (
        "- JÃ¤mfÃ¶r kvittona och se vilka som passerar/failar",
        "- Compare receipts and see which pass/fail",
    ),
    (
        "- Analysera vilka checks som Ã¤r mest kritiska",
        "- Analyze which checks are most critical",
    ),
    (
        "# TrÃ¤na olika modeller och kÃ¶r verifiering",
        "# Train different models and run verification",
    ),
    (
        'print("ğŸ§ª Mitt experiment: JÃ¤mfÃ¶r olika modeller")',
        'print("ğŸ§ª My experiment: Compare different models")',
    ),
    (
        "# TODO: Implementera loop som trÃ¤nar och verifierar varje modell",
        "# TODO: Implement a loop that trains and verifies each model",
    ),
    # 00 â€” remaining Swedish print statements
    ('print("\\nğŸ“ˆ TrÃ¤ningsgrafer:")', 'print("\\nğŸ“ˆ Training curves:")'),
    (
        'print("\\nâš ï¸ TrÃ¤ningsgrafer missing â€“ run trÃ¤ningen fÃ¶rst.")',
        'print("\\nâš ï¸ Training curves missing â€“ run training first.")',
    ),
    (
        'print("\\nâ„¹ï¸ INT8-kvantisering kan fallera pÃ¥ vissa miljÃ¶er. I denna lektion Ã¤r **FP32** godkÃ¤nt; verify accepterar fallback.")',
        'print("\\nâ„¹ï¸ INT8 quantization may fail on some environments. In this lesson **FP32** is accepted; verify accepts fallback.")',
    ),
    # 00 â€” miscellaneous headings and phrases from the user's list
    ("# Kontrollera att modellen skapades", "# Check that the model was created"),
    ("# Visa trÃ¤ningsgrafer", "# Show training curves"),
    ("# KÃ¶r utvÃ¤rdering", "# Run evaluation"),
    (
        "# KÃ¶r verifiering och generera kvitto",
        "# Run verification and generate receipt",
    ),
    ("Done!â€¦ NÃ¤sta steg", "Done!â€¦ Next steps"),
    ("Verifieringskvitto", "Verification receipt"),
    ("Visa kvitto", "Show receipt"),
    ("Kontroller", "Checks"),
    ("Latensbenchmark", "Latency Benchmark"),
    ("Kvantisering (INT8)", "Quantization (INT8)"),
    ("UtvÃ¤rdering & Verifiering", "Evaluation & Verification"),
    (
        'print("\\nâš ï¸ Confusion matrix missing â€“ run utvÃ¤rderingen fÃ¶rst.")',
        'print("\\nâš ï¸ Confusion matrix missing â€“ run evaluation first.")',
    ),
    # 02 â€” remaining Swedish print
    (
        'print(f"ğŸ§ª Mitt experiment: warmup={WARMUP_RUNS}, runs={BENCHMARK_RUNS}")',
        'print(f"ğŸ§ª My experiment: warmup={WARMUP_RUNS}, runs={BENCHMARK_RUNS}")',
    ),
    # 04 â€” ensure Swedish prints replaced
    ('print("\\nğŸ” Kontroller:")', 'print("\\nğŸ” Checks:")'),
    ('print("\\nğŸ“ Genererade filer:")', 'print("\\nğŸ“ Generated files:")'),
]


def replace_text(text: str) -> str:
    for old, new in REPLACEMENTS:
        text = text.replace(old, new)
    return text


def process_notebook(path: Path) -> bool:
    data = json.loads(path.read_text(encoding="utf-8"))
    changed = False
    for cell in data.get("cells", []):
        src = "".join(cell.get("source", []))
        new_src = replace_text(src)
        if new_src != src:
            cell["source"] = [line for line in new_src.splitlines(keepends=True)]
            changed = True
    if changed:
        path.write_text(
            json.dumps(data, ensure_ascii=False, indent=1), encoding="utf-8"
        )
    return changed


def main(argv: list[str]) -> int:
    if len(argv) < 2:
        print("Usage: fix_language_notebooks.py <notebook.ipynb|directory> [more ...]")
        return 2
    any_changed = False
    targets: list[Path] = []
    for arg in argv[1:]:
        p = Path(arg)
        if not p.exists():
            print(f"[WARN] Not found: {p}")
            continue
        if p.is_dir():
            targets.extend(sorted(p.rglob("*.ipynb")))
        else:
            targets.append(p)

    if not targets:
        print("[WARN] No notebooks found to process")
        return 0

    for nb_path in targets:
        changed = process_notebook(nb_path)
        print(f"[OK] {nb_path} â€“ {'updated' if changed else 'no changes'}")
        any_changed = any_changed or changed
    return 0 if any_changed else 0


if __name__ == "__main__":
    raise SystemExit(main(sys.argv))
